{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8814f45e-937d-41a5-aad7-fe56e6a9e2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initialize Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98641baf-1672-42d3-9433-879cc36236f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/21 16:07:10 INFO mlflow.tracking.fluent: Experiment with name '/Users/tbhavya054@gmail.com/product_performance_model_v1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and tools are ready.\n"
     ]
    }
   ],
   "source": [
    "# Standard Data Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# MLflow Experiment Tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Scikit-Learn Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Spark ML Tools\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression as SparkLR\n",
    "\n",
    "# --- Configuration: Tell MLflow where to save our work ---\n",
    "user_name = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "mlflow.set_experiment(f\"/Users/{user_name}/product_performance_model_v1\")\n",
    "\n",
    "print(\"Environment and tools are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "447051fb-6110-4609-803c-af8ff470e021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db338320-eb7c-47d2-ab54-3d5313f80d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the data from cleaned table\n",
    "table_name = \"ecommerce.fact_product_performance\"\n",
    "spark_df = spark.table(table_name)\n",
    "\n",
    "# Prepare Pandas data for Scikit-Learn experimentation\n",
    "# Define input features (X) and the target to predict (y)\n",
    "# Split the data: 80% for training and 20% for testing\n",
    "\n",
    "df = spark_df.toPandas()\n",
    "X = df[[\"views\", \"revenue\"]] \n",
    "y = df[\"purchases\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare distributed Spark data for pipeline\n",
    "train_spark, test_spark = spark_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28d5bf94-92e5-433c-aa85-cac7f8252145",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Experimentation & Performance Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61295a97-2115-4309-aa30-19c1f706eca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully tracked linear\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully tracked decision_tree\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully tracked random_forest\n\n--- Model Performance Comparison ---\nModel: linear | R2 Score: 0.9300\nModel: decision_tree | R2 Score: 0.8162\nModel: random_forest | R2 Score: 0.9332\n\nThe best model is 'random_forest' with an R2 of 0.9332\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store results for final comparison\n",
    "results = []\n",
    "\n",
    "# Define and compare 3 different models to test \n",
    "models = {\n",
    "    \"linear\": LinearRegression(),\n",
    "    \"decision_tree\": DecisionTreeRegressor(max_depth=5),\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=f\"{name}_experiment\"):\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        \n",
    "        # Persisting the metrics and model signature\n",
    "        mlflow.log_metric(\"r2_score\", score)\n",
    "        signature = infer_signature(X_test, model.predict(X_test))\n",
    "        mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "        \n",
    "        # Add the name and score to results list\n",
    "        results.append((name, score))\n",
    "        print(f\"Successfully tracked {name}\")\n",
    "\n",
    "# Comparison and Selection of ml model\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "\n",
    "# Loop through the results list and print each one\n",
    "for name, score in results:\n",
    "    print(f\"Model: {name} | R2 Score: {score:.4f}\")\n",
    "\n",
    "# identify the model with the highest score\n",
    "best_model_name, best_model_score = max(results, key=lambda x: x[1])\n",
    "print(f\"\\nThe best model is '{best_model_name}' with an R2 of {best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5790e6be-16c0-4e68-a363-ce395753a3b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Build the Spark Pipeline (Using Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "451e3dad-46c7-4992-bfde-fa08d261f245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is trained using the best model (Random Forest).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor as SparkRF\n",
    "\n",
    "# Group 'views' and 'revenue' into a single features column\n",
    "assembler = VectorAssembler(inputCols=[\"views\", \"revenue\"], outputCol=\"features\")\n",
    "\n",
    "# Set up the Random Forest model (our winner)\n",
    "rf_spark = SparkRF(featuresCol=\"features\", labelCol=\"purchases\")\n",
    "\n",
    "# Create the pipeline (the assembly line)\n",
    "pipeline = Pipeline(stages=[assembler, rf_spark])\n",
    "\n",
    "# Train the model using Spark data\n",
    "pipeline_model = pipeline.fit(train_spark)\n",
    "\n",
    "print(\"Pipeline is trained using the best model (Random Forest).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43b999bb-5716-456f-88ec-3c2915e78593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Application & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edcf300e-f350-431c-aab2-cf5170842812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>views</th><th>revenue</th><th>purchases</th><th>prediction</th></tr></thead><tbody><tr><td>19722</td><td>4129.620000000001</td><td>36</td><td>185.16164334143232</td></tr><tr><td>48774</td><td>119711.03999999994</td><td>318</td><td>482.6030897051977</td></tr><tr><td>1248</td><td>0.0</td><td>0</td><td>1.5253590910544628</td></tr><tr><td>36</td><td>0.0</td><td>0</td><td>0.004111100405512255</td></tr><tr><td>13236</td><td>0.0</td><td>0</td><td>163.68523446723057</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         19722,
         4129.620000000001,
         36,
         185.16164334143232
        ],
        [
         48774,
         119711.03999999994,
         318,
         482.6030897051977
        ],
        [
         1248,
         0.0,
         0,
         1.5253590910544628
        ],
        [
         36,
         0.0,
         0,
         0.004111100405512255
        ],
        [
         13236,
         0.0,
         0,
         163.68523446723057
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "views",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "revenue",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "purchases",
         "type": "\"long\""
        },
        {
         "metadata": "{\"ml_attr\": {}}",
         "name": "prediction",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predictions Completed Successfully\n"
     ]
    }
   ],
   "source": [
    "# Apply the pipeline to the test data to get results\n",
    "final_predictions = pipeline_model.transform(test_spark)\n",
    "\n",
    "# Show the real values vs. what the model calculated\n",
    "display(final_predictions.select(\"views\", \"revenue\", \"purchases\", \"prediction\").limit(5))\n",
    "\n",
    "print(\"Model Predictions Completed Successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY 13 ML & DE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}